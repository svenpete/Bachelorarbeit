{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BvL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tSHN49ygD0Mf",
        "wj1LFu3_dLKm",
        "HuCMNXSHI6eK"
      ],
      "mount_file_id": "11NzwyWjOBUFcPN7GDpk5jcwlv-VSLnAB",
      "authorship_tag": "ABX9TyOWFXzEQ8aYGHFK+mIBC2DO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svenpete/Bachelorarbeit/blob/main/BvL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnbNGXiOwJza"
      },
      "source": [
        "## **Datenaufbereitung einer industriellen Reinigungsanlage**\n",
        "# Der Niagara DFS             27.7.2018 \n",
        "\n",
        "Das folgendende Colab-Notebook wird zur Datenaufbereitung von Maschinendaten, einer industriellen Reinigungsanlage verwendet. Bei der industriellen Reinigungsanlge handelt es sich um eine Niagara DFS der Firna BvL Oberflächentechnik. Diese Taktanlage wird für industrielle Komponenten bzw. Bauteile eingesetzt, bei denen eine sehr hohe technischen Sauberkeit maßgebend ist. \n",
        "\n",
        "Unter dem Begriff Technische Sauberkeit ist die hinreichend geringe Kontamination sauberkeitssensibler technischer Bauteile mit schädlichen Partikeln zu verstehen. ... die korrekte Funktion des Bauteils bzw. der Baugruppe beeinträchtigen oder verhindern können. (Wikipedia stand 13.07.2021)\n",
        "\n",
        "Im folgenden werden die Maschinendaten so transformiert & manipuliert, dass diese mit Hilfe von maschinellen Lernverfahren verarbeitet werden können. Zunächst muss dafür eine Bibliothek zur Datenaufbereitung und -analyse gewählt werden. \n",
        "\n",
        "Die Datenaufbereitung findet in Python statt, als Bibliothek zur zur Datenaufbereitung und -anlyse wird Pandas verwendet. Das Framework zur Realisierung der maschinellen Lernverfahren ist Tensorflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGcE8x2Gkw9K"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzazvnMzN6mm"
      },
      "source": [
        "# Was sind diese Maschinendaten?\n",
        "Bei den Maschinendaten handelt es sich um Sensoren, welche intern und extern an der Reinigungsanlage angebracht wurden. Diese Sensoren zeichnen unteranderem:\n",
        "\n",
        "Einheit = Bar \n",
        "1. Druck der Wasch-, Spülpumpe 1 & 2, Waschbox \n",
        "2. Druck vor/nach Filter nach Wasch-, Spülpumpe 1 & 2, Waschbox   \n",
        "3. Differenzdruck Wasch-, Spülpumpe 1 & 2, Waschbox \n",
        "4. Kammerdruck\n",
        "\n",
        "Einheit = Celsius\n",
        "5. Temperatur der Vakuumtrockner 1 & 2 \n",
        "6. Temperatur von Waschtank, Spültank 1 & 2 \n",
        "7. Temperatur der Waschbox\n",
        "\n",
        "Einheit = Zustandslos (Libellen für  Wasch-, Spülpumpe 1 & 2)\n",
        "6. Verschmutzung des Wassers = Libelle Fluid\n",
        "7. Verschmutzung des Wassers mit Öl = Libelle Oil\n",
        "8. Reinigeranteil im Wassser = Libelle Cleaner \n",
        "\n",
        "Einheit = Sonstige\n",
        "9. Taktzeit\n",
        "10. Werkstückzähler \n",
        "11. Maschinenzustand\n",
        "\n",
        "Einheit = S ( Simens)\n",
        "12. Leitwert Wasch-, Spülpumpe 1 & 2, Waschbox \n",
        "\n",
        "\n",
        "Insgesamt werden 23 verschiedene Sensoriken erfasst. Einige Sensoren zeichnen während des gesamten Zeitraums eines Waschvorgangs Daten auf. Wiederrum andere Sensoren, zeichnen Daten nur während eines Teilprozesses vom Waschgang auf z.B. der Druck der Spülpumpe 1 vor dem Filter tritt nur während des Teilprozesses \"Spülen 1\" auf.\n",
        "\n",
        "\n",
        "\n",
        "# Erfassung der Maschinendaten\n",
        "Die Maschinendaten werden von einem Datalogger erfasst. Dieser erfasst eine Änderungen wenn der vorherige Wert sich um 5% geändert hat oder 5 Minuten vergangen sind. Die Daten werden als CSV-Format gespeichert. Es wird für jeden Monat eine neue CSV angelegt. \n",
        "\n",
        "\n",
        "# Problem Datalogger\n",
        "Durch das spezifizierte Verhalten des Dataloggers,kann die Anzahl an Sensormesswerten für verschiedene Waschgänge stark variieren.\n",
        "Zu einem ist es wichtig für jeden Waschgang eine einheitliche Anzahl an Sensormesswerten zu haben. \n",
        "Für die Maschinendaten eine Datei mit allen Sensormesswerten für den gesamten Zeitraums anzulegen. (Header der CSV ist 4 Zeilen groß) Hierdurch lassen sich statischtische Auswertungen und Visualisierungen später einfacher und schneller anwenden.\n",
        "\n",
        "\n",
        "# Laden der Maschinendaten\n",
        "\n",
        "Zunächst werden die Maschinendaten in ein Datenframe geladen. Das Datenframe aus der Python Bibliothek \"Pandas\" bietet umfangreiche Funktionalitäten zur Manipulation und Transformierung von Daten was es sehr Mächtig macht und deshalb zur Datenaufbereitung verwendet wird.\n",
        "Anschließend werden Metadaten des Datenframes abgerufen geladen über den:\n",
        "\n",
        "1. Shape = Drückt Zeilen und Spaltencount des Datenframes aus\n",
        "2. Head = Gibt die ersten 5 Zeilen der Datenframes zurück\n",
        "3. Columms = Namen aller Spalten\n",
        "4. dtype = Datentypen der einzlenen Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIYriWjyNdmg",
        "outputId": "b4752067-f531-450b-e610-67882ffed927"
      },
      "source": [
        "# Get the libary\n",
        "import pandas as pd\n",
        "# loading data from google drive \n",
        "df_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Testing.csv', parse_dates=['Timestring'],sep=\";\",low_memory=False, header=0, cache_dates=True)\n",
        "print(df_data.shape)\n",
        "print(df_data.columns)\n",
        "print(df_data.dtypes)\n",
        "print(df_data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8274229, 10)\n",
            "Index(['New_ID', 'Index', 'Var_Name', 'Timestring', 'Seconds', 'Milliseconds',\n",
            "       'Value', 'Day of Week', 'Sensorname', 'Date2'],\n",
            "      dtype='object')\n",
            "New_ID                   int64\n",
            "Index                  float64\n",
            "Var_Name                object\n",
            "Timestring      datetime64[ns]\n",
            "Seconds                float64\n",
            "Milliseconds           float64\n",
            "Value                   object\n",
            "Day of Week             object\n",
            "Sensorname              object\n",
            "Date2           datetime64[ns]\n",
            "dtype: object\n",
            "   New_ID  Index  ...                Sensorname      Date2\n",
            "0       0    0.0  ...  Temperatur Vakuumpumpe 2 2020-02-05\n",
            "1       1    1.0  ...       Leitwert Spültank 2 2020-02-05\n",
            "2       2    2.0  ...       Leitwert Spültank 1 2020-02-05\n",
            "3       3    3.0  ...  Temperatur Vakuumpumpe 1 2020-02-05\n",
            "4       4    4.0  ...        Leitwert Waschtank 2020-02-05\n",
            "\n",
            "[5 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaF47uSIxDn3"
      },
      "source": [
        "# Laden der Waschergebnisse\n",
        " Als nächstes werden die Waschergebnisse geladen. Diese werden regelmäßig Stichprobenartig entnommen und im Labor untersucht. Dabei wird das Waschgut in einem Labor, auf die technische Sauberkeit überprüft (s.O.). Es wird zwischen i.O. und n.i.O. unterschieden. Dafür  ausschlaggebened sind die Partikel auf der Öberfläche nach einem Waschgang. \n",
        "\n",
        " 1. Das Waschergebnis ist i.O. wenn alle Partikel < 600 nm\n",
        " 2. Das Waschergebnis ist n.i.O. wenn ein Partikel > 600 nm\n",
        "\n",
        "Die Waschergebnisse werden für den gesamten Tag betrachtet. Dadurch kann die KI später mehrere hunderte Cyclen als nur ein paar wenige. \n",
        "\n",
        "Neben dem Datum und dem Waschergebniss wird auch noch das gewaschenen Bauteil gespeichert. Auf Grund der Ähnlichkeit der Bauteile und Stichproben wird immer vom gleichen Bauteil ausgegangen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EKBYmvty-KY",
        "outputId": "d4277a1d-734b-4137-f8a9-077dc2b09c67"
      },
      "source": [
        "df_results = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Ratings.csv',parse_dates=['Date'], sep=\";\",low_memory=False, header=0, cache_dates=True)\n",
        "print(df_results.shape)\n",
        "print(df_results.head())\n",
        "print(df_results.dtypes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22, 3)\n",
            "        Date     Component  Rating\n",
            "0 2020-09-15    Hauptwelle   i. O.\n",
            "1 2020-09-23    Hauptwelle   i. O.\n",
            "2 2020-09-29    Hauptwelle   i. O.\n",
            "3 2020-10-01  Hauptwelle 2   i. O.\n",
            "4 2020-10-01  Hauptwelle 1  i. O. \n",
            "Date         datetime64[ns]\n",
            "Component            object\n",
            "Rating               object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET4s30-8OQLE"
      },
      "source": [
        "# Zusammenfügen der Maschinendaten und Waschergebnissen\n",
        "Im diesem Abschnitt werden nun die Maschinendaten mit den Waschergebnissen zusammengefügt. \n",
        "1. Da die Maschinendaten nur einen Timestamp besitzen, wird eine zusätzliche Spalte mit einem Datum hinzugefügt.\n",
        "2. Danach wird mit dem Datum der Maschinendaten ein \"Left Join\" mit dem Datum der Waschergebnissen durchgeführt.\n",
        "3. Die Maschinendaten enthalten nun Waschergebnissen für "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQzs_6wTT8f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebd9974-127b-4c30-9a63-9229b6057158"
      },
      "source": [
        "# change dtypes for merge\n",
        "df_results['Date'] = pd.to_datetime(df_results['Date'])\n",
        "\n",
        "# add column to machine data and change dtype for merge otherwise no result\n",
        "df_data['Date2'] = df_data['Timestring'].dt.date\n",
        "df_data['Timestring'] = pd.to_datetime(df_data['Timestring'])\n",
        "df_data['Date2'] = pd.to_datetime(df_data['Date2'])\n",
        "\n",
        "# get shapes\n",
        "print(df_results.shape)\n",
        "print(df_data.shape)\n",
        "\n",
        "# Left Join is needed\n",
        "df = df_data.merge(df_results, left_on='Date2', right_on='Date', how='left', sort='False')\n",
        "\n",
        "# delete rows from dataframe to store\n",
        "df.drop(columns=['New_ID', 'Index', 'Seconds', 'Milliseconds', 'Day of Week', 'Date2', 'Sensorname'], inplace=True, axis=1)\n",
        "\n",
        "# get first columns and store results in onedrive  \n",
        "print(df.head(5))\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/Data/Merged_Data.csv', sep=';', index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22, 3)\n",
            "(8274229, 10)\n",
            "New_ID                0\n",
            "Index                 0\n",
            "Var_Name              0\n",
            "Timestring            0\n",
            "Seconds               0\n",
            "Milliseconds          0\n",
            "Value                 0\n",
            "Day of Week           0\n",
            "Sensorname            0\n",
            "Date2                 0\n",
            "Date            7750835\n",
            "Component       7750835\n",
            "Rating          7750835\n",
            "dtype: int64\n",
            "(8301246, 13)\n",
            "          Var_Name          Timestring Value Date Component Rating\n",
            "0      temp_vp2_vc 2020-02-05 11:34:44    54  NaT       NaN    NaN\n",
            "1  med_cond_rt2_wc 2020-02-05 11:35:20  6016  NaT       NaN    NaN\n",
            "2   med_cond_rt_wc 2020-02-05 11:35:22  8043  NaT       NaN    NaN\n",
            "3       temp_vp_wc 2020-02-05 11:35:29    55  NaT       NaN    NaN\n",
            "4   med_cond_wt_wc 2020-02-05 11:35:41  8983  NaT       NaN    NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O00d9Ln_pIY2"
      },
      "source": [
        "# Transformieren der Maschinendaten\n",
        "Die Maschinendaten werden vom Datalogger tabellarisch und chronologisch untereinander gespeichert. Was beim Mergen bereits zu sehen war. Damit die Sensordaten als Features für maschinelle Lernverfahren verwendet werden kann, sollte die Sensornamen als Spalten transformiert werden.\n",
        "\n",
        "Jeder Sensor erhält eine Spalte mit seinem Namen. In dieser Spalte wird der Wert für den jeweiligen Zeitpunkt chronologisch gespeichert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQVWC1wr2kgj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "# get data and check types\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Merged_Data.csv',parse_dates=['Timestring'],sep=\";\",low_memory=False, header=0, cache_dates=True)\n",
        "\n",
        "#get  unique sensornames\n",
        "name_arr = df['Var_Name'].unique()\n",
        "\n",
        "\n",
        "df_transformed_machinedata = pd.DataFrame()\n",
        "\n",
        "for name in name_arr:\n",
        "\n",
        "  # get dataframe for each sensor \n",
        "  df_tmp = df.loc[df['Var_Name'] == name, ['Timestring', 'Value']]\n",
        "  df_tmp.set_index('Timestring', inplace=True)\n",
        "\n",
        "  # rename label from value to sensorname\n",
        "  df_tmp.rename(columns = {'Value' : name}, inplace=True)\n",
        " \n",
        "  # concat dataframe piece horizontal\n",
        "  df_transformed_machinedata = pd.concat([df_transformed_machinedata,df_tmp],)\n",
        "  \n",
        "#indexing for sorting transformend machinedata \n",
        "df_transformed_machinedata.reset_index(inplace=True)\n",
        "df_transformed_machinedata.set_index('Timestring', inplace=True)\n",
        "df_transformed_machinedata.sort_index(inplace=True)\n",
        "df_transformed_machinedata.to_csv('/content/drive/MyDrive/Colab Notebooks/Data/Sensordata_ordered.csv', sep=';', index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dL__XUDpQuD"
      },
      "source": [
        "# Problem der Prozesszeiten von Waschgänge \n",
        "Die Ermittlung der Prozesszeiten von Waschgänge und die daraus hervorgehende Strukturierung der Daten ist sehr schwierig. \n",
        "\n",
        "Die Prozesszeiten der Waschgänge varriert, dies kann mit Fehler beim Ab- oder Antransport eines Waschgutes entstehen. Oder am HMI der Reinigungsanlage wurden die Prozesszeiten umgestellt. \n",
        "Die Prozesszeiten sowie änderungen daran werden nicht gespeichert.\n",
        "\n",
        "-> Die Prozesszeit für ein Waschgang kann jedoch anhand des Werkstückzählers und der Waschpumpe bestimmt.\n",
        "\n",
        "# Ermittlung der dynamischen Prozesszeiten von Waschgänge \n",
        "Im folgenden wird das Vorgehen zur Bestimmung der dynamischen Prozesszeiten für Waschgänge erläutert. Der Sensoriken:\n",
        "\n",
        "1.Werkstückzähler (odata_count_wc) = Dient als inkrementeller Zähler bis dato der gereinigten Waschgüter. Wird am Ende jedes Waschgangs erst erhöht.\n",
        "\n",
        "Aussagen Werkstückzähler\n",
        "Max - Min = Anzahl aller Waschgänge\n",
        "Numerische Nummerierung ab 1 = Aktuellen Waschgang \n",
        "\n",
        "\n",
        "\n",
        "2. Druck vor Filter Waschpumpe (pres_wp_fi_wc) = Der Waschgang beginnt immer zuerst mit dem Teilprozess Waschen. Der Sensor für den Druck vor dem Filter der Waschpumpe sollte ansteigen und der Datenlogger speichert den Wert ab, wegen der 5% Regelung von Wertänderungen. Dies hat zur Folge, dass bei Start des Teilprozesses Waschen immer Wert von 0,1 Bar gespeichert wird. Es kann vorkommen, dass dieser Wert in einigen Szenarien auch 0,2 Bar beträgt. Deshalb wird 0,2 als Obergrenze für den Start des Waschgangs.\n",
        "\n",
        "Formel\n",
        "x <= 0.2 = Startprozess \n",
        "\n",
        "# Problematik zu 2\n",
        "Die Waschpumpe wird im Teilprozess Waschen als erstes vom Düsenrahmen verwendet und 2-3 Minuten später dann nochmals fürs Fluten der Waschkammer. Hier würde die Logik aus dem Absatz davor nicht greifen, weil die Waschpumpe zu einer falschen Aussage führen würde.\n",
        "\n",
        "\n",
        "# Lösugen mit delta Timestamp\n",
        "\n",
        "# Endwert \n",
        "Die Zeitdifference zwischen den Werkstückzählern und den Druck vor Filter Waschpumpe kann zur Validierung von Datenpunkten verwendet werden. Zu lange und zu kurze Zeitintervalle werden erstmals nicht berücksichtigt mit dieser Methode.\n",
        "\n",
        "Als Ober- und Untergrenze für den Werkstückzähler wird verwendet:\n",
        "\n",
        "Erwarungswert - Varianz = Untergrenze\n",
        "Erwarungswert + Varianz = Obergrenze ( noch keine Obergrenze Verhalten noch erforschen)\n",
        " \n",
        "Durchschnittlicher Waschgang beträgt ca. 24-25 Min.\n",
        "(Auftreten von odata_count_wc)\n",
        "\n",
        "#Startwert \n",
        "Für den Startzeitpunkt des Waschgangs sollte eine Obergrenze für den zeitlichen Abstand dieser Sensorwerte gesetzt werden. \n",
        "Die Obergrenze für das Timedelta sollte der Abstand zum letzten Sensorwert des letzten Waschgangs von \"Druck vor Filter Waschpumpe\" sein.\n",
        "\n",
        "1. Durchschnittlich dauert die Düsenreinigung ca. 2.40 - 3.20 Minuten\n",
        "2. Durchschnittlich dauert die Düsenreinigung ca. 3.10 Minuten\n",
        "3. Durchschnittlich dauert das Fluten der Waschkammer ca. 1.10 Minuten\n",
        "\n",
        "Insgesamt = 7,40 Minuten Waschen\n",
        "\n",
        "-> Die Obergrenze sollte niemals kleiner sein als die Durchschnittliche Zeit der aufgeführten 3 Punkte. Der Wert für die Obergrenze der Deltatime der Waschpumpe sollte nicht größer als oder gleich der Obergrenze für den Werkstückzähler sein. Der Wert sollte zwischen [12.50 - 21.30] liegen. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps8E63vhoUO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "f9f52cae-3d03-4f03-fa35-2c0adeed6fb6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "#read data and use specified columms\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Sensordata_ordered.csv', usecols=['Timestring', 'odata_count_wc', 'pres_wp_fi_wc'], parse_dates=['Timestring'],sep=\";\",low_memory=False, header=0, cache_dates=True)\n",
        "\n",
        "#sort data if not sorted \n",
        "df.set_index('Timestring', inplace=True)\n",
        "df.sort_index()\n",
        "\n",
        "#get value and nan value count\n",
        "print(df.count())\n",
        "print(df.odata_count_wc.isnull().sum())\n",
        "\n",
        "#delete data which has more than 1 nan in its column\n",
        "df.dropna(thresh=1, inplace=True)\n",
        "\n",
        "#replace , with . so you can these values as floats\n",
        "df['pres_wp_fi_wc'] = df['pres_wp_fi_wc'].str.replace(',', '.').astype(float)\n",
        "\n",
        "#apply used to cast objects to numeric values in dataframe \n",
        "df.apply(pd.to_numeric)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pres_wp_fi_wc     372955\n",
            "odata_count_wc     10408\n",
            "dtype: int64\n",
            "8290838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pres_wp_fi_wc</th>\n",
              "      <th>odata_count_wc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Timestring</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:35:59</th>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:36:01</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:36:01</th>\n",
              "      <td>3.8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:36:02</th>\n",
              "      <td>9.4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:36:02</th>\n",
              "      <td>7.4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-26 08:00:49</th>\n",
              "      <td>6.8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-26 08:00:49</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-26 08:00:49</th>\n",
              "      <td>9.8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-26 08:00:50</th>\n",
              "      <td>1.4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-05-26 08:00:58</th>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>383363 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     pres_wp_fi_wc  odata_count_wc\n",
              "Timestring                                        \n",
              "2020-02-05 11:35:59            0.1             NaN\n",
              "2020-02-05 11:36:01            2.0             NaN\n",
              "2020-02-05 11:36:01            3.8             NaN\n",
              "2020-02-05 11:36:02            9.4             NaN\n",
              "2020-02-05 11:36:02            7.4             NaN\n",
              "...                            ...             ...\n",
              "2021-05-26 08:00:49            6.8             NaN\n",
              "2021-05-26 08:00:49            5.0             NaN\n",
              "2021-05-26 08:00:49            9.8             NaN\n",
              "2021-05-26 08:00:50            1.4             NaN\n",
              "2021-05-26 08:00:58            0.1             NaN\n",
              "\n",
              "[383363 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSHN49ygD0Mf"
      },
      "source": [
        "# Bestimmung des Startzeitpunktes vom Waschgang\n",
        "Brechnung der Deltatime für Durck vor Filter Waschpumpe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uyCOptxcyXX",
        "outputId": "d46e93f0-8414-4e3a-bafd-e99f8fe4b61a"
      },
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "#press indicates the start of a process \n",
        "press_value_series = df['pres_wp_fi_wc']\n",
        "\n",
        "#drop empty values | inplace = store changes to dataframe\n",
        "press_value_series.dropna(inplace=True)\n",
        "\n",
        "#generate df for delta calc\n",
        "df_press = pd.DataFrame(press_value_series)\n",
        "\n",
        "#store timestamp for accessing as value \n",
        "df_press['delta'] = df_press.index\n",
        "\n",
        "# shifts the value delta calc.\n",
        "df_press['delta_time'] = df_press.delta.diff()\n",
        "df_press.dropna(inplace=True)\n",
        "\n",
        "#get delta_time_series for vald.\n",
        "delta_time_value_series = df_press['delta_time']\n",
        "\n",
        "print(df_press.describe())\n",
        "print(df_press)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       pres_wp_fi_wc                 delta_time\n",
            "count  372954.000000                     372954\n",
            "mean        6.350054  0 days 00:01:50.237452876\n",
            "std         4.279299  0 days 02:07:22.810508291\n",
            "min         0.100000            0 days 00:00:00\n",
            "25%         2.500000            0 days 00:00:00\n",
            "50%         6.400000            0 days 00:00:01\n",
            "75%         9.400000            0 days 00:00:08\n",
            "max        16.200000           44 days 10:17:48\n",
            "                     pres_wp_fi_wc               delta      delta_time\n",
            "Timestring                                                            \n",
            "2020-02-05 11:36:01            2.0 2020-02-05 11:36:01 0 days 00:00:02\n",
            "2020-02-05 11:36:01            3.8 2020-02-05 11:36:01 0 days 00:00:00\n",
            "2020-02-05 11:36:02            9.4 2020-02-05 11:36:02 0 days 00:00:01\n",
            "2020-02-05 11:36:02            7.4 2020-02-05 11:36:02 0 days 00:00:00\n",
            "2020-02-05 11:36:02            5.6 2020-02-05 11:36:02 0 days 00:00:00\n",
            "...                            ...                 ...             ...\n",
            "2021-05-26 08:00:49            6.8 2021-05-26 08:00:49 0 days 00:00:00\n",
            "2021-05-26 08:00:49            5.0 2021-05-26 08:00:49 0 days 00:00:00\n",
            "2021-05-26 08:00:49            9.8 2021-05-26 08:00:49 0 days 00:00:00\n",
            "2021-05-26 08:00:50            1.4 2021-05-26 08:00:50 0 days 00:00:01\n",
            "2021-05-26 08:00:58            0.1 2021-05-26 08:00:58 0 days 00:00:08\n",
            "\n",
            "[372954 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj1LFu3_dLKm"
      },
      "source": [
        "#Bestimmung des Endzeitpunktes vom Waschgang\n",
        "Brechnung der Deltatime für den Werkstückzähler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY_SXtKPHGvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542dc8d9-9e00-4eb8-dc56-b039ac3502aa"
      },
      "source": [
        "#to determine ende of washprocess cycle\n",
        "odata_series = df['odata_count_wc']\n",
        "\n",
        "#drop empty values\n",
        "odata_series = odata_series.dropna()\n",
        "\n",
        "#generate df for delta calc\n",
        "df_odata_count  = pd.DataFrame(odata_series)\n",
        "\n",
        "#store timestamp for accessing as value \n",
        "df_odata_count['delta'] = df_odata_count.index\n",
        "\n",
        "# shifts the value delta calc.\n",
        "df_odata_count['delta_time'] = df_odata_count.delta.diff()\n",
        "\n",
        "print(df_odata_count.describe())\n",
        "print(df_odata_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       odata_count_wc                 delta_time\n",
            "count    10408.000000                      10407\n",
            "mean     20130.770177  0 days 01:05:50.143172864\n",
            "std       3139.647660  0 days 12:49:19.722942746\n",
            "min      14846.000000            0 days 00:00:00\n",
            "25%      17446.750000            0 days 00:22:49\n",
            "50%      20008.500000            0 days 00:23:43\n",
            "75%      22784.250000            0 days 00:24:38\n",
            "max      26067.000000           45 days 04:41:20\n",
            "                     odata_count_wc               delta      delta_time\n",
            "Timestring                                                             \n",
            "2020-02-05 12:37:03         14846.0 2020-02-05 12:37:03             NaT\n",
            "2020-02-05 12:40:12         14847.0 2020-02-05 12:40:12 0 days 00:03:09\n",
            "2020-02-05 13:03:47         14848.0 2020-02-05 13:03:47 0 days 00:23:35\n",
            "2020-02-05 13:27:37         14849.0 2020-02-05 13:27:37 0 days 00:23:50\n",
            "2020-02-05 13:53:16         14850.0 2020-02-05 13:53:16 0 days 00:25:39\n",
            "...                             ...                 ...             ...\n",
            "2021-05-26 04:42:20         26063.0 2021-05-26 04:42:20 0 days 00:23:56\n",
            "2021-05-26 05:04:57         26064.0 2021-05-26 05:04:57 0 days 00:22:37\n",
            "2021-05-26 07:03:04         26065.0 2021-05-26 07:03:04 0 days 01:58:07\n",
            "2021-05-26 07:25:40         26066.0 2021-05-26 07:25:40 0 days 00:22:36\n",
            "2021-05-26 07:49:23         26067.0 2021-05-26 07:49:23 0 days 00:23:43\n",
            "\n",
            "[10408 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuCMNXSHI6eK"
      },
      "source": [
        "# Ermittlung & Validation der Waschgangsintervalle\n",
        "Bestimmung von Waschgangsintervalle bei industriellen Reinigungsanlagen anhand von Sensoriken.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk1qpP71I5_D",
        "outputId": "a9f1678f-e25f-4ddd-9ae4-93afbeffa8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import datetime\n",
        "\n",
        "\n",
        "#timedelta for comparison\n",
        "cap = timedelta(minutes=10, seconds=1)\n",
        "cap_odata = timedelta(minutes=17, seconds=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#filter timedeltas from start and end \n",
        "start_cycle = df_press.loc[(df_press['delta_time'] > cap ) & (df_press['pres_wp_fi_wc'] <= 0.2)].index.to_list()\n",
        "end_cycle = df_odata_count.loc[df_odata_count['delta_time'] > cap_odata].index.to_list()\n",
        "\n",
        "\n",
        "\n",
        "df_cycle_data = []\n",
        "cycle_number = 0 # counts washcycles\n",
        "data_counter = 0  # \n",
        "\n",
        "# iterate over odata_count_wc timestrings \n",
        "for end_date in end_cycle:\n",
        "  \n",
        "\n",
        "  # iterate over washpump timestrings\n",
        "  for start_date in start_cycle:\n",
        "   \n",
        "    \n",
        "    if data_counter == 0:\n",
        "      \n",
        "      #store information for dataframe \n",
        "      df_cycle_data.append([str(start_date), str(end_date), str(cycle_number)])\n",
        "      data_counter = data_counter + 1    \n",
        "      continue\n",
        "    \n",
        "    #check if bigger than remove and get new endindex\n",
        "    if start_date < end_date:\n",
        "      data_counter = data_counter + 1\n",
        "      continue\n",
        "\n",
        "    break\n",
        "  \n",
        "  #delete used dates for performance obvious\n",
        "  del start_cycle[:data_counter]\n",
        "  cycle_number = cycle_number + 1 \n",
        "  data_counter = 0  \n",
        "  \n",
        "#store results to csv\n",
        "df_cycle= pd.DataFrame(df_cycle_data, columns =['Start', 'End', 'Cycle'])\n",
        "df_cycle.to_csv('Waschzyklen.csv', index=False, sep=';')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    688\u001b[0m             raise AssertionError(\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;34mf\"{len(content)} columns\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: 4 columns passed, passed data had 3 columns",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8d2e816f36dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#store results to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdf_cycle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cycle_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'End'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cycle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mdf_cycle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Waschzyklen.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         return _list_of_dict_to_arrays(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 4 columns passed, passed data had 3 columns"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eog8daJ1pXUC"
      },
      "source": [
        "# Visualisierung und Analyse der Waschzyklen "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8oiKqA0Lx2gw",
        "outputId": "ed1efdec-2c84-4027-d21c-64cbda24de12"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Start</th>\n",
              "      <th>End</th>\n",
              "      <th>Cycle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-02-05 12:17:40</td>\n",
              "      <td>2020-02-05 13:03:47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-05 13:08:30</td>\n",
              "      <td>2020-02-05 13:27:37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-05 13:34:06</td>\n",
              "      <td>2020-02-05 13:53:16</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-05 13:57:54</td>\n",
              "      <td>2020-02-05 14:17:05</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-05 14:21:48</td>\n",
              "      <td>2020-02-05 14:43:38</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10331</th>\n",
              "      <td>2021-05-26 04:23:12</td>\n",
              "      <td>2021-05-26 04:42:20</td>\n",
              "      <td>10331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10332</th>\n",
              "      <td>2021-05-26 04:45:56</td>\n",
              "      <td>2021-05-26 05:04:57</td>\n",
              "      <td>10332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10333</th>\n",
              "      <td>2021-05-26 06:43:58</td>\n",
              "      <td>2021-05-26 07:03:04</td>\n",
              "      <td>10333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10334</th>\n",
              "      <td>2021-05-26 07:06:40</td>\n",
              "      <td>2021-05-26 07:25:40</td>\n",
              "      <td>10334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10335</th>\n",
              "      <td>2021-05-26 07:30:20</td>\n",
              "      <td>2021-05-26 07:49:23</td>\n",
              "      <td>10335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10336 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Start                  End  Cycle\n",
              "0      2020-02-05 12:17:40  2020-02-05 13:03:47      0\n",
              "1      2020-02-05 13:08:30  2020-02-05 13:27:37      1\n",
              "2      2020-02-05 13:34:06  2020-02-05 13:53:16      2\n",
              "3      2020-02-05 13:57:54  2020-02-05 14:17:05      3\n",
              "4      2020-02-05 14:21:48  2020-02-05 14:43:38      4\n",
              "...                    ...                  ...    ...\n",
              "10331  2021-05-26 04:23:12  2021-05-26 04:42:20  10331\n",
              "10332  2021-05-26 04:45:56  2021-05-26 05:04:57  10332\n",
              "10333  2021-05-26 06:43:58  2021-05-26 07:03:04  10333\n",
              "10334  2021-05-26 07:06:40  2021-05-26 07:25:40  10334\n",
              "10335  2021-05-26 07:30:20  2021-05-26 07:49:23  10335\n",
              "\n",
              "[10336 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trxU3Ds_zV8I"
      },
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Sensordata_ordered.csv', parse_dates=['Timestring'],sep=\";\",low_memory=False, header=0, cache_dates=True)\n",
        "test.set_index('Timestring', inplace=True)\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNTBVQDkcmRq"
      },
      "source": [
        "test['Timestring'] = test.index\n",
        "test['Start'] = test.Timestring.isin(start_cycle)\n",
        "test['End'] = test.Timestring.isin(end_cycle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "GzZfj25poT3Q",
        "outputId": "d9645ece-fc0b-4c0d-a500-485d691db888"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp_vp2_vc</th>\n",
              "      <th>med_cond_rt2_wc</th>\n",
              "      <th>med_cond_rt_wc</th>\n",
              "      <th>temp_vp_wc</th>\n",
              "      <th>med_cond_wt_wc</th>\n",
              "      <th>odata_osta_wc</th>\n",
              "      <th>pres_wp_fi_wc</th>\n",
              "      <th>pres_wp_fo_wc</th>\n",
              "      <th>pres_air_wc</th>\n",
              "      <th>pres_wp_diff_wc</th>\n",
              "      <th>temp_rt_wc</th>\n",
              "      <th>temp_wt_wc</th>\n",
              "      <th>temp_wp_at</th>\n",
              "      <th>pres_wp_fi_at</th>\n",
              "      <th>pres_wp_fo_at</th>\n",
              "      <th>pres_wp_diff_at</th>\n",
              "      <th>pres_rp_fi_wc</th>\n",
              "      <th>pres_rp_fo_wc</th>\n",
              "      <th>pres_rp_diff_wc</th>\n",
              "      <th>pres_rp2_fi_wc</th>\n",
              "      <th>pres_rp2_fo_wc</th>\n",
              "      <th>pres_rp2_diff_wc</th>\n",
              "      <th>odata_count_wc</th>\n",
              "      <th>odata_cyti_wc</th>\n",
              "      <th>med_lo_wt_wc</th>\n",
              "      <th>med_lo_rt_wc</th>\n",
              "      <th>med_lo_rt2_wc</th>\n",
              "      <th>med_lc_wt_wc</th>\n",
              "      <th>med_lc_rt_wc</th>\n",
              "      <th>med_lc_rt2_wc</th>\n",
              "      <th>med_lf_wt_wc</th>\n",
              "      <th>med_lf_rt_wc</th>\n",
              "      <th>med_lf_rt2_wc</th>\n",
              "      <th>temp_rt2_wc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Timestring</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:34:44</th>\n",
              "      <td>54.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:35:50</th>\n",
              "      <td>59.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:37:11</th>\n",
              "      <td>64.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:38:31</th>\n",
              "      <td>69.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-05 11:39:53</th>\n",
              "      <td>74.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     temp_vp2_vc  med_cond_rt2_wc  ...  med_lf_rt2_wc  temp_rt2_wc\n",
              "Timestring                                         ...                            \n",
              "2020-02-05 11:34:44         54.0              NaN  ...            NaN          NaN\n",
              "2020-02-05 11:35:50         59.0              NaN  ...            NaN          NaN\n",
              "2020-02-05 11:37:11         64.0              NaN  ...            NaN          NaN\n",
              "2020-02-05 11:38:31         69.0              NaN  ...            NaN          NaN\n",
              "2020-02-05 11:39:53         74.0              NaN  ...            NaN          NaN\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "Son0aylsal04",
        "outputId": "2a507b84-e9cb-4a4f-c192-b7252ca553f7"
      },
      "source": [
        "# print(test.loc[test['Start'] == True])\n",
        "test['cycle_end'] = ((test['End'] != test['End'].shift(1)).cumsum()) \n",
        "test['cycle_start'] = ((test['Start'] != test['Start'].shift(1)).cumsum()) \n",
        "test['cycle_match'] = ((test['Start'] == test['End'].shift(1)).cumsum()) \n",
        "test\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'End'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f95b3fcf02df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(test.loc[test['Start'] == True])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cycle_end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'End'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'End'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cycle_start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cycle_match'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'End'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'End'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzP61lH4JEz_"
      },
      "source": [
        "Visualisierung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQME0C4Wi1Mw"
      },
      "source": [
        "df_press.boxplot(column=['delta_time'], by=['delta'])\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 480\n",
        "ts = pd.Series(np.random.randn(n), index=pd.date_range(start=\"2020-02-05\", periods=n, freq=\"H\"))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5))\n",
        "seaborn.boxplot(ts.index.dayofyear, ts, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed_GcJTtkvTb"
      },
      "source": [
        "test = pd.Period()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xb2ERRWku5Z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "026TG7fLs0Wa",
        "outputId": "ac77bf32-5da5-41eb-8ad8-a9a21c512c62"
      },
      "source": [
        "print(press_value_series)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timestring\n",
            "2020-02-05 11:36:01     2.0\n",
            "2020-02-05 11:36:01     3.8\n",
            "2020-02-05 11:36:02     7.4\n",
            "2020-02-05 11:36:02     9.4\n",
            "2020-02-05 11:36:02    12.0\n",
            "                       ... \n",
            "2020-02-11 14:26:38     7.9\n",
            "2020-02-11 14:26:39    14.0\n",
            "2020-02-11 14:26:44    11.6\n",
            "2020-02-11 14:26:44     8.7\n",
            "2020-02-11 14:27:04     9.1\n",
            "Name: pres_wp_fi_wc, Length: 7857, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oyBBW-SeVYq"
      },
      "source": [
        "Auswahl des ersten Wert als erster Wert der geordeneten Sensordaten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "GQ0qIf_SwwWL",
        "outputId": "96235ed8-9ede-45ca-ddd4-39387f564528"
      },
      "source": [
        "from datetime import timedelta\n",
        "#previo = odata_series.po\n",
        "print(last)\n",
        "\n",
        "for index, value in press_value_series.items():\n",
        "  \n",
        "  if delta_time_value_series.get(index) > cap & value <= 0.2 :\n",
        "    press_value_series.get(index)\n",
        "    print(index)\n",
        "    #print(pandas)\n",
        "    #time delta \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1f7a0e1b9c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpress_value_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mdelta_time_value_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.2\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpress_value_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'datetime.timedelta' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1155ToAERecH"
      },
      "source": [
        "\n",
        "df_press.delta_time.resample('H').plot()\n",
        "#resample('15Min').mean()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXiMZKQH2SSJ"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "#testing.isnull().sum()\n",
        "df['temp_wt_wc'] = pd.to_numeric(df['temp_wt_wc'])\n",
        "print(df.shape)\n",
        "print(df.resample('15Min').mean())\n",
        "\n",
        "\n",
        "\n",
        "#testing['temp_wt_wc'].plot(style='k')\n",
        "\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "PNhH9-AcHMzq",
        "outputId": "83e6040d-9877-4811-d98c-f1c0ed8553bd"
      },
      "source": [
        "print(df.shape)\n",
        "testing.odata_count_wc.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8301246, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-3c2f1b08ff65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modata_count_wc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    947\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# no non-numeric frames or series allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no numeric data to plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;31m# GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p8jTuHSmMqL"
      },
      "source": [
        "df.isnull().sum()\n",
        "print(df.shape)\n",
        "print(df.dropna(how='any').shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IlCQ1VsiyGE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "843a32b1-a131-4be4-c421-c84cab9153bd"
      },
      "source": [
        "df_results['Date'] = pd.to_datetime(df_results['Date'])\n",
        "df_data['Date2'] = df_data['Timestring'].dt.date\n",
        "df_data['Date2'] = pd.to_datetime(df_data['Date2'])\n",
        "print(df_results.shape)\n",
        "print(df_data.shape)\n",
        "df = df_data.merge(df_results, left_on='Date2', right_on='Date', how='left', sort='False')\n",
        "\n",
        "df.drop(columns=['New_ID', 'Index', 'Seconds', 'Milliseconds', 'Day of Week', 'Date2', 'Date', 'Sensorname'], inplace=True, axis=1)\n",
        "print(df.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-92f410530536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestring'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_eiRibnD6Ir"
      },
      "source": [
        "df.isnull().sum()\n",
        "print(df.shape)\n",
        "#print(df.dropna(how='any').shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAbumf__D2PM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwRjq89Ntufc"
      },
      "source": [
        "\n",
        "#df_t.set_index('Timestring', inplace=True)\n",
        "\n",
        "x = df.iloc[ : , :-1].values\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQW1itwB2XcR"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "x[ : ,0] = label_encoder.fit_transform(x[ :, 0])\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llk8oRY2OwQx"
      },
      "source": [
        "Mergen der Maschinendaten + Waschergebnisse mit einem Dummy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2wbtTGp46vX"
      },
      "source": [
        "#df_t.set_index(['Timestring', 'Var_Name'], inplace=True)\n",
        "dummy = pd.get_dummies(df['Var_Name'])\n",
        "print(dummy)\n",
        "dataset = pd.concat([df, dummy], axis=1)\n",
        "print(dataset)\n",
        "#dataset.drop( columns=['Var_Name', 'pres_'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IApxV0A23nTT"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehotencoder = OneHotEncoder()\n",
        "x = onehotencoder.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0avT6TFOylq"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "for value in end_cycle:\n",
        "  print(value)\n",
        "  text = str(value)\n",
        "  np.datetime64('2002-06-28T01:00:00.000000000+0100').astype(datetime)\n",
        "  \n",
        "def parse_dates(date):\n",
        "  date_format = \"%Y-%m-%d %H:%M:%S\"\n",
        "  d_value = value // 10**9\n",
        "  date2 = int(date)\n",
        "  print(date2)\n",
        "  p_date = datetime.datetime.fromtimestamp(date2).strftime('%Y-%m-%d %H:%M:%S')\n",
        "  parsed_dates.append(p_date)\n",
        "\n",
        "  return parsed_date\n",
        "\n",
        "\n",
        "# x = [0, 1, 2]\n",
        "# y = ''.join(map(str, end_cycle))\n",
        "# z = int(y)\n",
        "\n",
        "\n",
        "# dates = parse_dates(end_cycle[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}